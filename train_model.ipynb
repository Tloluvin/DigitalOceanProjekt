{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54133e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "üèÉ‚Äç‚ôÇÔ∏è Halfmarathon Wroc≈Çaw - Model Training Pipeline\n",
    "\n",
    "Ten notebook zawiera kompletny pipeline do:\n",
    "1. Wczytywania danych z DigitalOcean Spaces\n",
    "2. Czyszczenia i przygotowania danych\n",
    "3. Feature engineering\n",
    "4. Trenowania modelu predykcyjnego\n",
    "5. Ewaluacji modelu\n",
    "6. Zapisywania modelu lokalnie i na DigitalOcean\n",
    "7. Zapisywania wykres√≥w do katalogu data/\n",
    "\"\"\"\n",
    "\n",
    "# ============ 1. IMPORT BIBLIOTEK I KONFIGURACJA ============\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Dodanie ≈õcie≈ºki do modu≈Ç√≥w utils\n",
    "sys.path.append('..')\n",
    "from utils.data_preprocessing import clean_data_for_modeling, prepare_features_for_model, merge_years_data\n",
    "\n",
    "# Konfiguracja wy≈õwietlania\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Za≈Çadowanie zmiennych ≈õrodowiskowych\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Biblioteki za≈Çadowane\")\n",
    "\n",
    "# ============ PLOT MANAGER - ZARZƒÑDZANIE WYKRESAMI ============\n",
    "\n",
    "class PlotManager:\n",
    "    \"\"\"ZarzƒÖdza zapisywaniem i katalogowaniem wykres√≥w\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir='data'):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.plots_dir = self.base_dir / 'training_plots'\n",
    "        self.manifest_path = self.base_dir / 'plots_manifest.json'\n",
    "        \n",
    "        # Tworzenie katalog√≥w\n",
    "        self.base_dir.mkdir(exist_ok=True)\n",
    "        self.plots_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Inicjalizacja manifestu\n",
    "        self.manifest = self._load_manifest()\n",
    "        print(f\"‚úÖ PlotManager gotowy. Katalog: {self.plots_dir}\")\n",
    "    \n",
    "    def _load_manifest(self):\n",
    "        \"\"\"Wczytuje istniejƒÖcy manifest lub tworzy nowy\"\"\"\n",
    "        if self.manifest_path.exists():\n",
    "            with open(self.manifest_path, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return {\n",
    "            'created': datetime.now().isoformat(),\n",
    "            'plots': []\n",
    "        }\n",
    "    \n",
    "    def save_plot(self, figure, filename, title, description):\n",
    "        \"\"\"Zapisuje wykres i dodaje do manifestu\"\"\"\n",
    "        plot_path = self.plots_dir / filename\n",
    "        figure.savefig(plot_path, dpi=100, bbox_inches='tight')\n",
    "        plt.close(figure)\n",
    "        \n",
    "        plot_entry = {\n",
    "            'filename': filename,\n",
    "            'title': title,\n",
    "            'description': description,\n",
    "            'saved_at': datetime.now().isoformat(),\n",
    "            'path': str(plot_path.relative_to(self.base_dir))\n",
    "        }\n",
    "        \n",
    "        self.manifest['plots'].append(plot_entry)\n",
    "        self._save_manifest()\n",
    "        \n",
    "        print(f\"   ‚úÖ Zapisano: {filename}\")\n",
    "        return plot_path\n",
    "    \n",
    "    def _save_manifest(self):\n",
    "        \"\"\"Zapisuje manifest do pliku JSON\"\"\"\n",
    "        with open(self.manifest_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.manifest, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Inicjalizacja\n",
    "plot_manager = PlotManager('data')\n",
    "\n",
    "# ============ 2. WCZYTYWANIE DANYCH Z DIGITALOCEAN SPACES ============\n",
    "\n",
    "BUCKET_NAME = \"dane-modul9\"\n",
    "\n",
    "# Inicjalizacja klienta S3 (DigitalOcean Spaces)\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    endpoint_url=os.getenv(\"AWS_ENDPOINT_URL_S3\")\n",
    ")\n",
    "\n",
    "print(\"üîó ≈ÅƒÖczenie z DigitalOcean Spaces...\")\n",
    "\n",
    "# Wczytanie danych\n",
    "wroclaw_2023_df = pd.read_csv(\n",
    "    f\"s3://{BUCKET_NAME}/dane-zadanie_modul9/halfmarathon_wroclaw_2023__final.csv\", \n",
    "    sep=\";\"\n",
    ")\n",
    "wroclaw_2024_df = pd.read_csv(\n",
    "    f\"s3://{BUCKET_NAME}/dane-zadanie_modul9/halfmarathon_wroclaw_2024__final.csv\", \n",
    "    sep=\";\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dane wczytane:\")\n",
    "print(f\"   - 2023: {len(wroclaw_2023_df)} wierszy\")\n",
    "print(f\"   - 2024: {len(wroclaw_2024_df)} wierszy\")\n",
    "\n",
    "# ============ 3. CZYSZCZENIE I PRZYGOTOWANIE DANYCH ============\n",
    "\n",
    "print(\"\\nüßπ Czyszczenie danych...\")\n",
    "print(\"\\n=== ROK 2023 ===\")\n",
    "df_2023_clean = clean_data_for_modeling(wroclaw_2023_df, 2023)\n",
    "\n",
    "print(\"\\n=== ROK 2024 ===\")\n",
    "df_2024_clean = clean_data_for_modeling(wroclaw_2024_df, 2024)\n",
    "\n",
    "# Po≈ÇƒÖczenie danych z obu lat\n",
    "print(\"\\n=== ≈ÅƒÑCZENIE DANYCH ===\")\n",
    "df_combined = pd.concat([df_2023_clean, df_2024_clean], ignore_index=True)\n",
    "df_combined['Year'] = df_combined['Rocznik'].apply(lambda x: 2023 if x < 2010 else 2024)\n",
    "\n",
    "print(f\"\\n‚úÖ Dane po≈ÇƒÖczone: {len(df_combined)} wierszy\")\n",
    "\n",
    "# ============ 4. EKSPLORACJA OCZYSZCZONYCH DANYCH ============\n",
    "\n",
    "print(\"\\nüìä Podstawowe statystyki oczyszczonych danych:\")\n",
    "print(f\"\\nRozmiar datasetu: {df_combined.shape}\")\n",
    "print(f\"\\nRozk≈Çad p≈Çci:\")\n",
    "print(df_combined['P≈Çeƒá'].value_counts())\n",
    "print(f\"\\nStatystyki wieku:\")\n",
    "print(df_combined['Wiek'].describe())\n",
    "print(f\"\\nStatystyki tempo:\")\n",
    "print(df_combined['Tempo'].describe())\n",
    "\n",
    "# Wizualizacja rozk≈Çad√≥w\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Rozk≈Çad tempa\n",
    "axes[0, 0].hist(df_combined['Tempo'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Tempo (min/km)')\n",
    "axes[0, 0].set_ylabel('Liczba')\n",
    "axes[0, 0].set_title('Rozk≈Çad tempa')\n",
    "axes[0, 0].axvline(df_combined['Tempo'].median(), color='red', linestyle='--', label='Mediana')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Rozk≈Çad wieku\n",
    "axes[0, 1].hist(df_combined['Wiek'], bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Wiek')\n",
    "axes[0, 1].set_ylabel('Liczba')\n",
    "axes[0, 1].set_title('Rozk≈Çad wieku')\n",
    "axes[0, 1].axvline(df_combined['Wiek'].median(), color='red', linestyle='--', label='Mediana')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Tempo vs Wiek\n",
    "axes[1, 0].scatter(df_combined['Wiek'], df_combined['Tempo'], alpha=0.3, s=10)\n",
    "axes[1, 0].set_xlabel('Wiek')\n",
    "axes[1, 0].set_ylabel('Tempo (min/km)')\n",
    "axes[1, 0].set_title('Tempo vs Wiek')\n",
    "\n",
    "# Tempo wed≈Çug p≈Çci\n",
    "df_combined.boxplot(column='Tempo', by='P≈Çeƒá', ax=axes[1, 1])\n",
    "axes[1, 1].set_xlabel('P≈Çeƒá')\n",
    "axes[1, 1].set_ylabel('Tempo (min/km)')\n",
    "axes[1, 1].set_title('Tempo wed≈Çug p≈Çci')\n",
    "axes[1, 1].get_figure().suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_manager.save_plot(\n",
    "    fig,\n",
    "    'exploratory_distributions.png',\n",
    "    'Rozk≈Çady danych wej≈õciowych',\n",
    "    'Analiza rozk≈Çad√≥w tempa, wieku i ich korelacji'\n",
    ")\n",
    "\n",
    "# ============ 5. PRZYGOTOWANIE FEATURE'√ìW I TARGET'A ============\n",
    "\n",
    "# Wyb√≥r feature'√≥w do modelu (ZOPTYMALIZOWANE na podstawie analizy)\n",
    "# Usuniƒôto: Has_Team (0.04% importance), First_5km_Fast (dubluje 5 km Tempo)\n",
    "feature_columns = [\n",
    "    'Gender_Numeric',        # P≈Çeƒá (0=K, 1=M) - 0.0% importance, ale szybko dostƒôpne\n",
    "    'Wiek',                  # Wiek - 0.3% importance, personalizacja\n",
    "    '5 km Tempo',            # Tempo na pierwszych 5km - 87.7% importance ‚≠ê\n",
    "    'Tempo Stabilno≈õƒá',      # Stabilno≈õƒá tempa - 11.9% importance ‚úÖ\n",
    "]\n",
    "\n",
    "print(\"\\nüìä U≈ºyte feature'y (po optymalizacji):\")\n",
    "print(\"   ‚úÖ 5 km Tempo: 87.7% importance - KLUCZOWY\")\n",
    "print(\"   ‚úÖ Tempo Stabilno≈õƒá: 11.9% importance - WA≈ªNY\")\n",
    "print(\"   ‚ö†Ô∏è  Wiek: 0.3% importance - personalizacja\")\n",
    "print(\"   ‚ö†Ô∏è  Gender_Numeric: 0.0% importance - demographics\")\n",
    "print(\"\\nüí° Usuniƒôto:\")\n",
    "print(\"   ‚ùå Has_Team: redundantny (ju≈º w 5 km Tempo)\")\n",
    "print(\"   ‚ùå First_5km_Fast: korelacja -0.786 z 5 km Tempo\")\n",
    "\n",
    "# Target - tempo na mecie\n",
    "target_column = 'Tempo'\n",
    "\n",
    "# Usuniƒôcie wierszy z brakujƒÖcymi warto≈õciami\n",
    "df_model = df_combined[feature_columns + [target_column]].dropna()\n",
    "\n",
    "print(f\"\\nüìä Dane do modelowania: {len(df_model)} wierszy\")\n",
    "print(f\"Feature'y: {feature_columns}\")\n",
    "print(f\"Target: {target_column}\")\n",
    "\n",
    "# Przygotowanie X i y\n",
    "X = df_model[feature_columns]\n",
    "y = df_model[target_column]\n",
    "\n",
    "print(f\"\\n‚úÖ X shape: {X.shape}\")\n",
    "print(f\"‚úÖ y shape: {y.shape}\")\n",
    "\n",
    "# ============ 6. PODZIA≈Å DANYCH NA TRAIN/TEST ============\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Podzia≈Ç danych:\")\n",
    "print(f\"   - Train: {len(X_train)} wierszy ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   - Test: {len(X_test)} wierszy ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Standaryzacja (opcjonalna, ale mo≈ºe poprawiƒá wyniki niekt√≥rych modeli)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n‚úÖ Dane przygotowane do trenowania\")\n",
    "\n",
    "# ============ 7. TRENOWANIE MODELI ============\n",
    "\n",
    "print(\"\\nüöÄ Trenowanie modeli...\")\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüìà Trenowanie: {name}...\")\n",
    "    \n",
    "    # Trenowanie\n",
    "    if name in ['Linear Regression', 'Ridge Regression']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Ewaluacja\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úÖ MAE: {mae:.4f}\")\n",
    "    print(f\"   ‚úÖ RMSE: {rmse:.4f}\")\n",
    "    print(f\"   ‚úÖ R¬≤: {r2:.4f}\")\n",
    "\n",
    "# ============ 8. POR√ìWNANIE MODELI ============\n",
    "\n",
    "# Dataframe z wynikami\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'MAE': [results[m]['mae'] for m in results.keys()],\n",
    "    'RMSE': [results[m]['rmse'] for m in results.keys()],\n",
    "    'R¬≤': [results[m]['r2'] for m in results.keys()]\n",
    "}).sort_values('MAE')\n",
    "\n",
    "print(\"\\nüìä Por√≥wnanie modeli:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Wizualizacja\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# MAE\n",
    "axes[0].bar(results_df['Model'], results_df['MAE'], color='steelblue', alpha=0.7)\n",
    "axes[0].set_ylabel('MAE')\n",
    "axes[0].set_title('Mean Absolute Error (ni≈ºszy = lepszy)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# RMSE\n",
    "axes[1].bar(results_df['Model'], results_df['RMSE'], color='coral', alpha=0.7)\n",
    "axes[1].set_ylabel('RMSE')\n",
    "axes[1].set_title('Root Mean Squared Error (ni≈ºszy = lepszy)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# R¬≤\n",
    "axes[2].bar(results_df['Model'], results_df['R¬≤'], color='green', alpha=0.7)\n",
    "axes[2].set_ylabel('R¬≤')\n",
    "axes[2].set_title('R¬≤ Score (wy≈ºszy = lepszy)')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_manager.save_plot(\n",
    "    fig,\n",
    "    'models_comparison.png',\n",
    "    'Por√≥wnanie wydajno≈õci modeli',\n",
    "    'Metryki MAE, RMSE, R¬≤ dla wszystkich wytrenowanych modeli'\n",
    ")\n",
    "\n",
    "# Najlepszy model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\nüèÜ Najlepszy model: {best_model_name}\")\n",
    "print(f\"   MAE: {results[best_model_name]['mae']:.4f} min/km\")\n",
    "print(f\"   RMSE: {results[best_model_name]['rmse']:.4f} min/km\")\n",
    "print(f\"   R¬≤: {results[best_model_name]['r2']:.4f}\")\n",
    "\n",
    "# ============ 9. FEATURE IMPORTANCE (dla Random Forest) ============\n",
    "\n",
    "if 'Random Forest' in results:\n",
    "    rf_model = results['Random Forest']['model']\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_columns,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nüìä Feature Importance (Random Forest):\")\n",
    "    print(feature_importance.to_string(index=False))\n",
    "    \n",
    "    # Wizualizacja\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance['Feature'], feature_importance['Importance'], \n",
    "             color='steelblue', alpha=0.7)\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Feature Importance - Random Forest')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_manager.save_plot(\n",
    "        fig,\n",
    "        'feature_importance.png',\n",
    "        'Wa≈ºno≈õƒá cech (Feature Importance)',\n",
    "        'Analiza wp≈Çywu poszczeg√≥lnych zmiennych na predykcjƒô'\n",
    "    )\n",
    "\n",
    "# ============ 10. ANALIZA PREDYKCJI ============\n",
    "\n",
    "# Predykcje vs warto≈õci rzeczywiste dla najlepszego modelu\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test, best_predictions, alpha=0.3, s=10)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', lw=2)\n",
    "axes[0].set_xlabel('Rzeczywiste tempo (min/km)')\n",
    "axes[0].set_ylabel('Przewidywane tempo (min/km)')\n",
    "axes[0].set_title(f'Predykcje vs Rzeczywiste - {best_model_name}')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram b≈Çƒôd√≥w\n",
    "errors = y_test - best_predictions\n",
    "axes[1].hist(errors, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(0, color='red', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('B≈ÇƒÖd predykcji (min/km)')\n",
    "axes[1].set_ylabel('Liczba')\n",
    "axes[1].set_title('Rozk≈Çad b≈Çƒôd√≥w predykcji')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_manager.save_plot(\n",
    "    fig,\n",
    "    'predictions_analysis.png',\n",
    "    'Analiza dok≈Çadno≈õci predykcji',\n",
    "    'Por√≥wnanie warto≈õci przewidywanych z rzeczywistymi oraz rozk≈Çad b≈Çƒôd√≥w'\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Statystyki b≈Çƒôd√≥w:\")\n",
    "print(f\"   ≈öredni b≈ÇƒÖd: {errors.mean():.4f} min/km\")\n",
    "print(f\"   Mediana b≈Çƒôdu: {errors.median():.4f} min/km\")\n",
    "print(f\"   Odchylenie std b≈Çƒôdu: {errors.std():.4f} min/km\")\n",
    "\n",
    "# ============ 11. ZAPISYWANIE MODELU LOKALNIE ============\n",
    "\n",
    "# Utworzenie katalogu models je≈õli nie istnieje\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Zapisanie najlepszego modelu\n",
    "model_filename = f'models/halfmarathon_model_{best_model_name.replace(\" \", \"_\").lower()}.pkl'\n",
    "scaler_filename = 'models/scaler.pkl'\n",
    "\n",
    "joblib.dump(best_model, model_filename)\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "\n",
    "print(f\"\\n‚úÖ Model zapisany lokalnie: {model_filename}\")\n",
    "print(f\"‚úÖ Scaler zapisany lokalnie: {scaler_filename}\")\n",
    "\n",
    "# Zapisanie informacji o modelu\n",
    "model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'features': feature_columns,\n",
    "    'mae': results[best_model_name]['mae'],\n",
    "    'rmse': results[best_model_name]['rmse'],\n",
    "    'r2': results[best_model_name]['r2'],\n",
    "    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'training_samples': len(X_train)\n",
    "}\n",
    "\n",
    "with open('models/model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=4)\n",
    "\n",
    "print(f\"‚úÖ Informacje o modelu zapisane: models/model_info.json\")\n",
    "\n",
    "# ============ 12. UPLOAD MODELU NA DIGITALOCEAN SPACES ============\n",
    "\n",
    "print(\"\\n‚òÅÔ∏è Wysy≈Çanie modelu na DigitalOcean Spaces...\")\n",
    "\n",
    "def upload_file_to_spaces(local_file, remote_file):\n",
    "    \"\"\"Upload pliku do DigitalOcean Spaces\"\"\"\n",
    "    try:\n",
    "        s3_client.upload_file(local_file, BUCKET_NAME, remote_file)\n",
    "        print(f\"   ‚úÖ Wys≈Çano: {remote_file}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå B≈ÇƒÖd: {e}\")\n",
    "        return False\n",
    "\n",
    "# Upload modelu\n",
    "upload_file_to_spaces(\n",
    "    model_filename, \n",
    "    f'models/halfmarathon_model_{best_model_name.replace(\" \", \"_\").lower()}.pkl'\n",
    ")\n",
    "\n",
    "# Upload scalera\n",
    "upload_file_to_spaces(\n",
    "    scaler_filename,\n",
    "    'models/scaler.pkl'\n",
    ")\n",
    "\n",
    "# Upload informacji o modelu\n",
    "upload_file_to_spaces(\n",
    "    'models/model_info.json',\n",
    "    'models/model_info.json'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Model wys≈Çany na DigitalOcean Spaces!\")\n",
    "\n",
    "# ============ 13. PODSUMOWANIE ============\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ PIPELINE ZAKO≈ÉCZONY POMY≈öLNIE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Podsumowanie:\")\n",
    "print(f\"   - Wytrenowano {len(models)} modeli\")\n",
    "print(f\"   - Najlepszy model: {best_model_name}\")\n",
    "print(f\"   - MAE: {results[best_model_name]['mae']:.4f} min/km\")\n",
    "print(f\"   - RMSE: {results[best_model_name]['rmse']:.4f} min/km\")\n",
    "print(f\"   - R¬≤: {results[best_model_name]['r2']:.4f}\")\n",
    "print(f\"\\nüíæ Model zapisany:\")\n",
    "print(f\"   - Lokalnie: {model_filename}\")\n",
    "print(f\"   - DigitalOcean: models/halfmarathon_model_*.pkl\")\n",
    "print(f\"\\nüìä Wykresy zapisane:\")\n",
    "print(f\"   - Katalog: data/training_plots/\")\n",
    "print(f\"   - Manifest: data/plots_manifest.json\")\n",
    "print(f\"\\nüöÄ Gotowe do wdro≈ºenia w aplikacji Streamlit!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055a986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zadanie_modul9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
